# -*- coding: utf-8 -*-
"""RGB-CNN-LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VkHbV_xkHI31MJoXWXNwZIdlmCygQKLU
"""

import os
import numpy as np
import cv2

!gdown https://drive.google.com/uc?id=1dzKYbGhLfPwBNKcPl7WgHpY8psvHiKIP

ls

!unzip RGB.zip

root_dir = 'RGB_main'
dest_dir = 'activity_data'

if not os.path.exists(dest_dir):
    os.mkdir(dest_dir)

data_dir_list = os.listdir(root_dir)

def vid_to_frames():
    for data_dir in data_dir_list:
        data_path = os.path.join(root_dir,data_dir)
        dest_data_path = os.path.join(dest_dir,data_dir)
        if not os.path.exists(dest_data_path):
            os.mkdir(dest_data_path)
        
        activity_list = os.listdir(data_path)
        
        for activity in activity_list:
            activity_path = os.path.join(data_path,activity)
            dest_activity_path = os.path.join(dest_data_path,activity)
            if not os.path.exists(dest_activity_path):
                os.mkdir(dest_activity_path)
            #print(dest_activity_path)
            write_frames(activity_path,dest_activity_path)
    
def write_frames(activity_path,dest_activity_path):
        vid_path = os.path.join(activity_path)
        print ('video path: ', vid_path)
        cap = cv2.VideoCapture(vid_path)
        dest_folder_path=dest_activity_path
        ret=True
        frame_num=0
        while ret:
            ret, img = cap.read()
            output_file_name = 'img_{:06d}'.format(frame_num) + '.png'
            output_file_path = os.path.join(dest_folder_path, output_file_name)
            print(output_file_path)
            frame_num += 1
            print("Frame no. ", frame_num)
            try:
                #cv2.imshow('img',img)
                cv2.waitKey(5)
                cv2.imwrite(output_file_path, img) # writing frames to defined location
            except Exception as e:
                print(e)
            if ret==False:
                cv2.destroyAllWindows()
                cap.release()

vid_to_frames()

os.mkdir('RGB_main')

for i in range(1,28):
  os.mkdir('RGB_main/'+str(i))

data_dir_list = os.listdir("RGB")

data

from shutil import copyfile
for data in data_dir_list:
  file=data.split('_')[0]
  fl=""
  for i in range(1,len(file)):
    fl=fl+file[i]
  
  np="RGB_main/"+str(fl)+"/"+data
  op="RGB/"+data
  copyfile(op,np)

dict1={}
dict2={}

import shutil 
dtr=os.listdir("activity_data")
for fldr in dtr:
  if not os.path.exists("utd/test/"+str(fldr)):
    os.mkdir("utd/test/"+str(fldr))
  if not os.path.exists("utd/train/"+str(fldr)):
    os.mkdir("utd/train/"+str(fldr))
  dict1[fldr]=0
  dict2[fldr]=0
  fl=os.listdir("activity_data/"+str(fldr))
  dict1[fldr]=len(fl)
  for f in fl:
    dict2[fldr]+=1
    pat="activity_data/"+str(fldr)+"/"+str(f)
    dpat="utd/"
    
    if dict2[fldr] <= dict1[fldr]/2:
      dpat+="train"
    else:
      dpat+="test"
    dpat+="/"
    dpat+=str(fldr)
    dpat+=("/"+str(f))
    shutil.copytree(pat, dpat)

import pandas as pd
import os

root_data_dir = 'utd'

num_classes = 27 
labels_name={'1' :0,
'2' :1,
'3' :2,
'4' :3,
'5' :4,
'6' :5,
'7' :6,
'8' :7,
'9' :8,
'10' :9,
'11' :10,
'12' :11,
'13' :12,
'14' :13,
'15' :14,
'16' :15,
'17' :16,
'18' :17,
'19' :18,
'20' :19,
'21' :20,
'22' :21,
'23' :22,
'24' :23,
'25' :24,
'26' :25,
'27' :26}

train_data_path = os.path.join('utd','train')
test_data_path = os.path.join('utd','test')

if not os.path.exists('data_files'):
    os.mkdir('data_files')
if not os.path.exists('data_files/train'):
    os.mkdir('data_files/train') 
if not os.path.exists('data_files/test'):
    os.mkdir('data_files/test')

rm -rf data_files

import heapq 
data_dir_list = os.listdir(train_data_path)
for data_dir in data_dir_list:
    label = labels_name[str(data_dir)]
    video_list = os.listdir(os.path.join(train_data_path,data_dir))
    for vid in video_list:

        train_df = pd.DataFrame(columns=['FileName', 'Label', 'ClassName'])
        img_list = os.listdir(os.path.join(train_data_path,data_dir,vid))
        cnt=0
        for img in img_list:
          cnt=cnt+1
        for i in range(cnt):
          strr=vid.split('.')[0]+'{:06d}'.format(i)+'.png'
          print(strr)

          img_path = os.path.join(train_data_path,data_dir,vid,strr)
          print(img_path)
          train_df = train_df.append({'FileName': img_path, 'Label': label,'ClassName':data_dir },ignore_index=True)
        file_name='{}_{}.csv'.format(data_dir,vid)
        #print(file_name)
        train_df.to_csv('data_files/train/{}'.format(file_name))

data_dir_list = os.listdir(train_data_path)
for data_dir in data_dir_list:
    label = labels_name[str(data_dir)]
    video_list = os.listdir(os.path.join(train_data_path,data_dir))
    for vid in video_list:
        train_df = pd.DataFrame(columns=['FileName', 'Label', 'ClassName'])
        img_list = os.listdir(os.path.join(train_data_path,data_dir,vid))
        for img in img_list:
            img_path = os.path.join(train_data_path,data_dir,vid,img)
            train_df = train_df.append({'FileName': img_path, 'Label': label,'ClassName':data_dir },ignore_index=True)
        file_name='{}_{}.csv'.format(data_dir,vid)
        train_df.to_csv('data_files/train/{}'.format(file_name))

data_dir_list = os.listdir(test_data_path)
for data_dir in data_dir_list:
    label = labels_name[str(data_dir)]
    video_list = os.listdir(os.path.join(test_data_path,data_dir))
    for vid in video_list:
        test_df = pd.DataFrame(columns=['FileName', 'Label', 'ClassName'])
        img_list = os.listdir(os.path.join(test_data_path,data_dir,vid))
        for img in img_list:
            img_path = os.path.join(test_data_path,data_dir,vid,img)
            test_df = test_df.append({'FileName': img_path, 'Label': label,'ClassName':data_dir },ignore_index=True)
        file_name='{}_{}.csv'.format(data_dir,vid)
        test_df.to_csv('data_files/test/{}'.format(file_name))

!pip install config

import pandas as pd
import cv2
import numpy as np
from sklearn.utils import shuffle
import os
from collections import deque
import copy
import matplotlib
import matplotlib.pyplot as plt
from keras.utils import np_utils
from config import Config

def file_generator(data_path,data_files,temporal_stride=3,temporal_length=40):
    '''
    data_files - list of csv files to be read.
    '''
    for f in data_files:       
        tmp_df = pd.read_csv(os.path.join(data_path,f))
        label_list = list(tmp_df['Label'])
        total_images = len(label_list) 
        if total_images>=temporal_length:
            num_samples = int((total_images-temporal_length)/temporal_stride)+1
            print ('num of samples from vid seq-{}: {}'.format(f,num_samples))
            img_list = list(tmp_df['FileName'])
        else:
            print ('num of frames is less than temporal length; hence discarding this file-{}'.format(f))
            continue

        start_frame = 0
        samples = deque()
        samp_count=0
        for img in img_list:
            samples.append(img)
            if len(samples)==temporal_length:
                samples_c=copy.deepcopy(samples)
                samp_count+=1
                for t in range(temporal_stride):
                    samples.popleft()
                yield samples_c,label_list[0]

def load_samples(data_cat='train',temporal_stride=3,temporal_length=40):
    data_path = os.path.join('data_files',data_cat)
    data_files = os.listdir(data_path)
    file_gen = file_generator(data_path,data_files,temporal_stride,temporal_length)
    iterator = True
    data_list = []
    while iterator:
        try:
            x,y = next(file_gen)
            x=list(x)
            data_list.append([x,y])
        except Exception as e:
            print ('the exception: ',e)
            iterator = False
            print ('end of data generator')
    return data_list

train_data = load_samples(data_cat='train',temporal_stride=3,temporal_length=40)

print ('Total number of train samples:',len(train_data))

train_data[0]

def shuffle_data(samples):
    data = shuffle(samples,random_state=2)
    return data

def preprocess_image(img):
    img = cv2.resize(img,(224,224))
    img = img/255
    return img

def data_generator(data,batch_size=10,temporal_padding='same',shuffle=False):              
    """
    Yields the next training batch.
    data is an array [[img1_filename,img2_filename...,img16_filename],label1], [image2_filename,label2],...].
    """
    num_samples = len(data)
    if shuffle:
        data = shuffle_data(data)
    while True:   
        for offset in range(0, num_samples, batch_size):
          #  print ('startring index: ', offset) 
            # Get the samples you'll use in this batch
            batch_samples = data[offset:offset+batch_size]
            # Initialise X_train and y_train arrays for this batch
            X_train = []
            y_train = []
            # For each example
            for batch_sample in batch_samples:
                # Load image (X)
                x = batch_sample[0]
                y = batch_sample[1]
                temp_data_list = []
                for img in x:
                   
                    try:
                        img = cv2.imread(img)
                        #print(img)
                        #apply any kind of preprocessing here
                        #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
                        img = preprocess_image(img)
                        temp_data_list.append(img)

                    except Exception as e:
                        print (e)
                        print ('error reading file: ',img)                      
                # Read label (y)
                #label = label_names[y]
                # Add example to arrays
                X_train.append(temp_data_list)
                y_train.append(y)
    
            # Make sure they're numpy arrays (as opposed to lists)
            X_train = np.array(X_train)
            #X_train = np.rollaxis(X_train,1,4)
            y_train = np.array(y_train)
            # convert to one hot encoding for training keras model
            y_train = np_utils.to_categorical(y_train, 27)
    
            # yield the next training batch            
            yield X_train, y_train

train_generator = data_generator(train_data,batch_size=2,shuffle=True)

x,y = next(train_generator)
print ('x shape: ',x.shape)
print ('y shape: ',y.shape)

x_0=x[0]
y_0=y[0]
print('x_0 shape: ',x_0.shape)
print('y_0 shape: ',y_0.shape)

Config.labels_to_class

activity = Config.labels_to_class[np.argmax(y_0)]
activity

num_of_images=40
fig=plt.figure(figsize=(8,8))	
plt.title("one sample with {} frames ; activity:{}".format(num_of_images,1))
subplot_num = int(np.ceil(np.sqrt(num_of_images)))
for i in range(int(num_of_images)):
    ax = fig.add_subplot(subplot_num, subplot_num, i+1)
    #ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter
    ax.imshow(x_0[i,:,:,::-1])
    plt.xticks([])
    plt.yticks([])
    plt.tight_layout()
plt.show()

1 import numpy
   2 
   3 def smooth(x,window_len=11,window='hanning'):
   4     """smooth the data using a window with requested size.
   5     
   6     This method is based on the convolution of a scaled window with the signal.
   7     The signal is prepared by introducing reflected copies of the signal 
   8     (with the window size) in both ends so that transient parts are minimized
   9     in the begining and end part of the output signal.
  10     
  11     input:
  12         x: the input signal 
  13         window_len: the dimension of the smoothing window; should be an odd integer
  14         window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'
  15             flat window will produce a moving average smoothing.
  16 
  17     output:
  18         the smoothed signal
  19         
  20     example:
  21 
  22     t=linspace(-2,2,0.1)
  23     x=sin(t)+randn(len(t))*0.1
  24     y=smooth(x)
  25     
  26     see also: 
  27     
  28     numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve
  29     scipy.signal.lfilter
  30  
  31     TODO: the window parameter could be the window itself if an array instead of a string
  32     NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.
  33     """ 
  34      
  35     if x.ndim != 1:
  36         raise ValueError, "smooth only accepts 1 dimension arrays."
  37 
  38     if x.size < window_len:
  39         raise ValueError, "Input vector needs to be bigger than window size."
  40         
  41 
  42     if window_len<3:
  43         return x
  44     
  45     
  46     if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:
  47         raise ValueError, "Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'"
  48     
  49 
  50     s=numpy.r_[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]
  51     #print(len(s))
  52     if window == 'flat': #moving average
  53         w=numpy.ones(window_len,'d')
  54     else:
  55         w=eval('numpy.'+window+'(window_len)')
  56     
  57     y=numpy.convolve(w/w.sum(),s,mode='valid')
  58     return y